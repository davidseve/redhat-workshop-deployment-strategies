# Canary deployment strategy with service mesh
include::_attributes.adoc[]

In the previous section, we executed a canary deployment using *Argo Rollouts* without https://argoproj.github.io/argo-rollouts/features/traffic-management/[traffic management]. When we set 10% weight it does not mean that 10% of the traffic goes to the new version. Because, as we explanted before, *Argo Rollouts* makes a best-effort attempt to achieve the percentage listed in the weight between the new and old versions.

To achieve the right percentage in each version, we are going to use traffic management with **Openshift Service Mesh** 

Moreover, we have another huge improvement. The back application is sending metrics to Prometheus. We will configure *Argo Rollouts* to use those metrics to decide if keep increasing the amount of traffic, that goes to the new version, or cancel the rollout.

To get progressive delivery based on the Prometheus metrics. We have an AnalysisTemplate that fetches the metrics and decide if go on or cancel the rollout.

[source,yaml,subs="+macros,+attributes"]
----
spec:
  metrics:
  - name: {{ include "service.name" . }}-prometheus-metric
    interval: 10s
    successCondition: len(result) == 0 || result[0] >= 0.95
    failureLimit: 2
    provider:
      prometheus:
        address: https://internal:<PROMETHEUS-PASSWORD>@prometheus.istio-system.svc.cluster.local:9090
        query: |
                    sum(irate( istio_requests_total{reporter="source",destination_service_name=~"dstrategies-back",response_code!~"5.*"}[30s] )) / sum(irate( istio_requests_total{reporter="source",destination_service_name=~"dstrategies-back"}[30s] ))
----

== Generate DStrategies APP GitOps Deployment Model

First of all, it is required to review a set of objects in our forked git repository to configure the deployment correctly for deploying our application following a GitOps model.

For this exercise, we are going to use Helm to render the different Kubernetes objects. Please follow the next section to understand the required objects and configurations.

=== Review and Modify Rollout strategy

We want that you define the steps to perform the canary deployment. You can choose the number of the steps and the percentage of traffic. To learn more about **Argo Rollouts**, please read https://argoproj.github.io/argo-rollouts/features/canary/[this].

Please edit a file named *./rhsm-canary/templates/dstrategies-back-rollout.yaml* to define **<SET-STEPS>** as you want and understand the canary deployment strategy:

[source,yaml,subs="+macros,+attributes"]
----
  strategy:
    canary:
      trafficRouting:
        istio:
          virtualService:
            routes:
            - primary
            name: {{ include "service.name" . }}
          destinationRule:
            name: {{ include "service.name" . }}
            canarySubsetName: canary
            stableSubsetName: stable
      steps:
        <SET-STEPS>
----

=== Modify Helm values

Finally, it is required to create a **Deployment** object to deploy the frontend application. This application helps us to test the canary rollout strategy from a web interface and see backend information.

To allow communication between the frontend and the backend, it is required to edit the file named *./rhsm-canary/edit.values.yaml* to add the required **<OCP_APPS_DOMAIN>**.

[source,yaml,subs="+macros,+attributes"]
----
service:
  image:
    version: V1.0.0
domain: <OCP_APPS_DOMAIN>
----


=== Obtain Red Hat Service Mesh Prometheus Password

To get Service Mesh Prometheus password, review the parameters table provided by the instructor. Then it is required to edit the file named *./rhsm-canary/templates/dstrategies-back-analysis-template.yaml* to add the required *<PROMETHEUS-PASSWORD>*.

[source,yaml,subs="+macros,+attributes"]
----
    provider:
      prometheus:
        address: https://internal:<PROMETHEUS-PASSWORD>@prometheus.istio-system.svc.cluster.local:9090
----

=== Commit and Push the Changes

Once all the files are configured correctly, it is time to commit and push all changes to the repository that you have just forked.

[.console-input]
[source,input,subs="+macros,+attributes"]
----
git add .
git commit -m "Configured DStrategies App deployment files for canary with Service Mesh strategy"
git push
----

== Deploy Dstrategies Application

We are going to create the application *dstrategies*, which we will use to test canary deployment with Service Mesh. Because we will make changes in the application's GitHub repository, we have to use the repository that you have just forked. Please edit the following yaml and set your own GitHub repository in the *reportURL*. Create a file called *application-dstrategies-canary-rhsm.yaml*

[.console-input]
[source,input,yaml,subs="+macros,+attributes"]
----
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: dstrategies-canary-service-mesh
  namespace: {user}-gitops-argocd
spec:
  destination:
    name: ''
    namespace: {user}-canary-service-mesh
    server: 'https://kubernetes.default.svc'
  source:
    path: rhsm-canary
    repoURL: https://github.com/change_me/dstrategies-app-deployment
    targetRevision: HEAD    
    helm:
      valueFiles:
        - edit.values.yaml
  project: default
  syncPolicy:
    automated:
      prune: false
      selfHeal: true
----

[.console-input]
[source,input,subs="+macros,+attributes"]
----
oc apply -f application-dstrategies-canary-rhsm.yaml
----

Looking at the Argo CD dashboard, you would notice that we have a new *dstrategies* application.
 
image::argocd_dstrategies-canary-service-mesh.png["ArgoCD Dstrategies"]

== Application architecture

To achieve canary deployment with *Cloud Native* applications using **Argo Rollouts** and *Openshift Service Mesh*, we have designed this architecture.

image::canary-service-mesh-rollout-step-0.png["Dstrategies initial status"]

OpenShift Components
TODO
- Routes and Services declared with the suffix -online
- Routes mapped only to the online services
- Services mapped to the rollout.

In Blue/Green deployment we always have an offline service to test the version that is not in production. In the case of canary deployment, we do not need it because progressively we will have the new version in production. 

We can also see the rollout´s status.

[.console-input]
[source,input,subs="+macros,+attributes"]
----
oc argo rollouts get rollout dstrategies-back --watch -n {user}-canary-service-mesh
----

[.console-output]
[source,input,subs="+macros,+attributes"]
----
NAME                                  KIND        STATUS     AGE  INFO
⟳ dstrategies-back                            Rollout     ✔ Healthy  38s  
└──# revision:1                                                   
   └──⧉ dstrategies-back-67fc9fb79b           ReplicaSet  ✔ Healthy  38s  stable
      ├──□ dstrategies-back-67fc9fb79b-4ql4z  Pod         ✔ Running  38s  ready:2/2
      ├──□ dstrategies-back-67fc9fb79b-7c4jw  Pod         ✔ Running  38s  ready:2/2
      ├──□ dstrategies-back-67fc9fb79b-lz86j  Pod         ✔ Running  38s  ready:2/2
      └──□ dstrategies-back-67fc9fb79b-xlkhp  Pod         ✔ Running  38s  ready:2/2
----

We have defined an active service 'dstrategies-back'. Final user will always use 'dstrategies-back'. When a new version is deployed **Argo Rollouts** create a new revision (ReplicaSet). The number of replicas in the new release increases based on the information in the steps, and the number of replicas in the old release decreases by the same number. But in this case the amount of traffic that is send to each version will be managed by the VirtualService.


== Test Dstrategies application
 
We have deployed the *dstrategies* with ArgoCD. We can test that it is up and running.

Visit the back route via your web browser https://dstrategies-back-{user}-canary-service-mesh-istio-system.apps.rollouts.sandbox1288.opentlc.com/dstrategies-back[URL]

IMPORTANT: It is required to accept *self-signed certificates* provided by Openshift

.Openshift Self-signed Certificates Warning
image::certs_warning.png[width=50%]
 
Then you can use the frontend https://dstrategies-frontend-{user}-canary-service-mesh-istio-system.apps.%CLUSTER%/[URL]

Visit the frontend route via your web browser, push - JUMP- button and ensure the following message is displaying on your screen:

.Frontend Interface
image::frontend-canary-service-mesh.png["Frontend Interface"]

Notice that in each microservice response we have added metadata information to see better the *version* of each application. This will help us to see the changes while we do the canary deployment.  We can see that the current version is *V1.0.0*.

== Dstrategies-back canary deployment

To test canary deployment we are going to do changes in the backend application dstrategies-back.

### Deploy dstrategies-back new version
 
We will deploy a new version *V2.0.0*. 

Before applying these changes, it is important to monitor the current version via the frontend. To track all canary processes, it is required to prepare the frontend to generate multiple requests. *If do not have multiple requests the back application will not generate traffic and the rollout will fail*. Remember that we are using the metrics to decide if we go on with the rollout or not. Without traffic we don't have metrics.

Visit the frontend route via your web browser, edit the number of *Calls Retries* to 10000 and push - JUMP- button and ensure the following message is displaying on your screen:

.Frontend Interface
image::frontend-canary-service-mesh-retries.png["Frontend Interface"]

**Argo Rollouts** will automatically deploy a new dstrategies-back revision. Based on the steps that you have defined, we will see how the traffic will go to the different versions.

We also encourage you to use https://kiali-istio-system.apps.%CLUSTER%/[Kiali] graph to see the percentages of the traffic that goes to each version. Log in with your Openshift lab-user and select you namespace.

.Kiali namespace
image::kiali-namespace.png["Kiali namespace]

Then go to 'Show Edge Labels' and select 'Requests Percentage'.

.Kiali labels
image::kiali-labels.png["Kiali labels]

We will see the dstrategies graph with 100% of the traffic going to V1.0.0

.Kiali graph V1
image::kiali-graph-v1.png["Kiali graph V1]

We have to edit the files *./rhsm-canary/edit.values.yaml* to modify the value *v1.0.0* to *V2.0.0*:

[.console-input]
[source,input,yaml,subs="+macros,+attributes"]
----
    version: V2.0.0' <---
----
[.console-input]

When you are ready to see all the changes on the fly. Push the changes to start the deployment.
[.console-input]
[source,input,subs="+macros,+attributes"]
----
git add .
git commit -m "Change dstrategies-back version to V2.0.0"
git push
----

ArgoCD will refresh the status after some minutes. If you don't want to wait you can refresh it manually from ArgoCD UI.

This is our current status (It can be different depending on the steps you have defined)):

image::canary-service-mesh-rollout-step-1.png["Dstrategies Step 1]

[.console-input]
[source,input,subs="+macros,+attributes"]
----
oc argo rollouts get rollout dstrategies-back --watch -n {user}-canary-service-mesh
----

[.console-output]
[source,input,subs="+macros,+attributes"]
----
NAME                                  KIND        STATUS     AGE    INFO
⟳ dstrategies-back                            Rollout     ॥ Paused   3m13s  
├──# revision:2                                                     
│  └──⧉ dstrategies-back-9dc6f576f            ReplicaSet  ✔ Healthy  8s     canary
│     └──□ dstrategies-back-9dc6f576f-fwq8m   Pod         ✔ Running  8s     ready:2/2
└──# revision:1                                                     
   └──⧉ dstrategies-back-67fc9fb79b           ReplicaSet  ✔ Healthy  3m13s  stable
      ├──□ dstrategies-back-67fc9fb79b-4ql4z  Pod         ✔ Running  3m13s  ready:2/2
      ├──□ dstrategies-back-67fc9fb79b-lz86j  Pod         ✔ Running  3m13s  ready:2/2
      └──□ dstrategies-back-67fc9fb79b-xlkhp  Pod         ✔ Running  3m13s  ready:2/2
----

On the front web page you will see how the versions change.

New revision:

.Frontend Interface
image::frontend-canary-service-mesh-v2.png["Frontend Interface"]

Old revision:


.Frontend Interface
image::frontend-canary-service-mesh.png["Frontend Interface"]

In Kiali, you can also see how the traffic going to each version changes.

.Kiali graph V2
image::kiali-graph-v2.png["Kiali graph V2]

### Deploy dstrategies-back new version rollout finished

When all the rollout steps have finished. **We have the new version V2.0.0 for all the users!!!**

image::canary-service-mesh-rollout-step-2.png["Dstrategies Step Rollback"]

New revision:

.Frontend Interface
image::frontend-canary-service-mesh-v2.png["Frontend Interface"]

### Rollback

Imagine that something goes wrong, we know that this never happens but just in case. We can do a very *quick rollback* just by undoing the change.

**Argo Rollouts** has an https://argoproj.github.io/argo-rollouts/generated/kubectl-argo-rollouts/kubectl-argo-rollouts_undo/[undo] command to do the rollback. In our opinion, we don't like this procedure because it is not aligned with GitOps. The changes that **Argo Rollouts** do does not come from git, so git is OutOfSync with what we have in Openshift.
In our case the commit that we have done not only changes the ReplicaSet but also the ConfigMap. The *undo* command only changes the ReplicaSet, so it does not work for us.

I recommend doing the changes in git. We will revert the last commit
[.console-input]
[source,input,subs="+macros,+attributes"]
----
git revert HEAD --no-edit
----

If we just revert the changes in git we will go back to the previous version. But **Argo Rollouts** will take this revert as a new release so it will do it throw the steps that we have configured. We want a *quick rollback* we don't want a step-by-step revert. To achieve the *quick rollback* we will configure **Argo Rollouts** without steps for the rollback.

In the file *./rhsm-canary/templates/dstrategies-back-rollout.yaml*  under the *steps* delete all the steps and only set one step *- setWeight: 100*:

[source,yaml,subs="+macros,+attributes"]
----
  strategy:
    canary:
      trafficRouting:
        istio:
          virtualService:
            routes:
            - primary
            name: {{ include "service.name" . }}
          destinationRule:
            name: {{ include "service.name" . }}
            canarySubsetName: canary
            stableSubsetName: stable
      steps:
        - setWeight: 100
----

Execute those commands to push the changes:

[.console-input]
[source,input,subs="+macros,+attributes"]
----
git add .
git commit -m "delete steps for rollback"
git push
----

**ArgoCD** will get the changes and apply them. **Argo Rollouts** will create a new revision with the previous version.

The rollback is done!

image::canary-service-mesh-rollout-step-rollback.png["Dstrategies Step Rollback"]

To test the  service, you can use the frontend https://dstrategies-frontend-{user}-canary-service-mesh-istio-system.apps.%CLUSTER%/[URL]

Visit the frontend route via your web browser, push - JUMP- button and ensure the following message is displaying on your screen:

.Frontend Interface
image::frontend-canary-service-mesh.png["Frontend Interface"]


To get the application ready for a new release we should configure again the  **Argo Rollouts** with the steps.

